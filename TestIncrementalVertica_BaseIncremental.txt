(cenv) sachin@sachin-ThinkBook-14-G2-ITL:~/Documents/VERTICA/dbt-vertica-3x/tests$ pytest functional/adapter/test_basic.py 
===================================================================================== test session starts =====================================================================================
platform linux -- Python 3.10.6, pytest-7.1.3, pluggy-1.0.0
rootdir: /home/sachin/Documents/VERTICA/dbt-vertica-3x, configfile: pytest.ini
plugins: dotenv-0.5.2
collected 1 item                                                                                                                                                                              

functional/adapter/test_basic.py F                                                                                                                                                      [100%]

========================================================================================== FAILURES ===========================================================================================
___________________________________________________________________________ TestIncrementalVertica.test_incremental ___________________________________________________________________________

self = <adapter.test_basic.TestIncrementalVertica object at 0x7f56eb6a9db0>, project = <dbt.tests.fixtures.project.TestProjInfo object at 0x7f56ed8fb490>

    def test_incremental(self, project):
        # seed command
>       results = run_dbt(["seed"])

/home/sachin/Documents/VERTICA/cenv/lib/python3.10/site-packages/dbt/tests/adapter/basic/test_incremental.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

args = ['seed'], expect_pass = True

    def run_dbt(args: List[str] = None, expect_pass=True):
        # Ignore logbook warnings
        warnings.filterwarnings("ignore", category=DeprecationWarning, module="logbook")
    
        # The logger will complain about already being initialized if
        # we don't do this.
        log_manager.reset_handlers()
        if args is None:
            args = ["run"]
    
        print("\n\nInvoking dbt with {}".format(args))
        res, success = handle_and_check(args)
    
        if expect_pass is not None:
>           assert success == expect_pass, "dbt exit state did not match expected"
E           AssertionError: dbt exit state did not match expected

/home/sachin/Documents/VERTICA/cenv/lib/python3.10/site-packages/dbt/tests/util.py:76: AssertionError
------------------------------------------------------------------------------------ Captured stdout setup ------------------------------------------------------------------------------------

=== Test project_root: /tmp/pytest-of-sachin/pytest-119/project0
19:19:42  Partial parse save file not found. Starting full parse.
------------------------------------------------------------------------------------- Captured log setup --------------------------------------------------------------------------------------
INFO     default_stdout:functions.py:222 19:19:42  Partial parse save file not found. Starting full parse.
DEBUG    configured_file:functions.py:220 19:19:42.700571 [debug] [MainThread]: Acquiring new vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:42.700760 [debug] [MainThread]: Acquiring new vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:42.700925 [debug] [MainThread]: Creating schema "_ReferenceKey(database='vmart', schema='test16664663828075989083_test_basic', identifier=None)"
DEBUG    configured_file:functions.py:220 19:19:42.707466 [debug] [MainThread]: Using vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:42.707634 [debug] [MainThread]: On _test: BEGIN
DEBUG    configured_file:functions.py:220 19:19:42.707739 [debug] [MainThread]: Opening a new connection, currently in state init
DEBUG    configured_file:functions.py:220 19:19:42.775001 [debug] [MainThread]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:42.783705 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.08 seconds
DEBUG    configured_file:functions.py:220 19:19:42.784289 [debug] [MainThread]: Using vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:42.784659 [debug] [MainThread]: On _test: create schema if not exists "test16664663828075989083_test_basic"
  
DEBUG    configured_file:functions.py:220 19:19:42.798846 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.01 seconds
DEBUG    configured_file:functions.py:220 19:19:42.800876 [debug] [MainThread]: On _test: COMMIT
DEBUG    configured_file:functions.py:220 19:19:42.801346 [debug] [MainThread]: Using vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:42.801705 [debug] [MainThread]: On _test: COMMIT
DEBUG    configured_file:functions.py:220 19:19:42.811370 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.01 seconds
DEBUG    configured_file:functions.py:220 19:19:42.811996 [debug] [MainThread]: On _test: Close
------------------------------------------------------------------------------------ Captured stdout call -------------------------------------------------------------------------------------


Invoking dbt with ['seed']
19:19:42  Running with dbt=1.3.0
19:19:42  Partial parse save file not found. Starting full parse.
19:19:43  Found 1 model, 0 tests, 0 snapshots, 0 analyses, 296 macros, 0 operations, 2 seed files, 1 source, 0 exposures, 0 metrics
19:19:43  
19:19:43  Concurrency: 4 threads (target='default')
19:19:43  
19:19:43  1 of 2 START seed file test16664663828075989083_test_basic.added ............... [RUN]
19:19:43  2 of 2 START seed file test16664663828075989083_test_basic.base ................ [RUN]
19:19:43  1 of 2 ERROR loading seed file test16664663828075989083_test_basic.added ....... [ERROR in 0.25s]
19:19:43  2 of 2 OK loaded seed file test16664663828075989083_test_basic.base ............ [Code: None, Rows: -1, Array Size: 1 in 0.28s]
19:19:43  
19:19:43  Finished running 2 seeds in 0 hours 0 minutes and 0.58 seconds (0.58s).
19:19:43  
19:19:43  Completed with 1 error and 0 warnings:
19:19:43  
19:19:43  Database Error in seed added (seeds/added.csv)
19:19:43    Severity: ROLLBACK, Message: Object "seed_rejects" already exists, Sqlstate: 42710, Routine: outputAlreadyExistsEreport, File: /data/jenkins/workspace/RE-ReleaseBuilds/RE-Knuckleboom/server/vertica/Commands/DDL.cpp, Line: 25505, Error Code: 4213, SQL: '/* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "node_id": "seed.incremental.added"} */          create table "VMart"."test16664663828075989083_test_basic"."added" ("id" integer,"name" varchar(9),"some_date" timestamp without time zone)   ;     -- dbt seed --              copy "VMart"."test16664663828075989083_test_basic"."added"         ("id", "name", "some_date")         from local \'/tmp/pytest-of-sachin/pytest-119/project0/seeds/added.csv\'         delimiter \',\'         enclosed by \'"\'         skip 1         abort on error         rejected data as table "VMart"."test16664663828075989083_test_basic".seed_rejects;        '
19:19:43    compiled Code at target/run/incremental/seeds/added.csv
19:19:43  
19:19:43  Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
-------------------------------------------------------------------------------------- Captured log call --------------------------------------------------------------------------------------
DEBUG    configured_file:functions.py:220 19:19:42.830000 [debug] [MainThread]: Connection '_test' was properly closed.
INFO     configured_file:functions.py:222 

============================== 2022-10-22 19:19:42.835648 | 3696c8d5-7b7d-4933-86b2-718e91c5e9c9 ==============================
19:19:42.835656 [info ] [MainThread]: Running with dbt=1.3.0
INFO     configured_std_out:functions.py:222 19:19:42  Running with dbt=1.3.0
DEBUG    configured_file:functions.py:220 19:19:42.835903 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/tmp/pytest-of-sachin/pytest-119/profile0', 'send_anonymous_usage_stats': False, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'show': False, 'which': 'seed', 'rpc_method': 'seed', 'indirect_selection': 'eager'}
DEBUG    configured_file:functions.py:220 19:19:42.836011 [debug] [MainThread]: Tracking: do not track
INFO     configured_file:functions.py:222 19:19:42.841504 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
INFO     configured_std_out:functions.py:222 19:19:42  Partial parse save file not found. Starting full parse.
DEBUG    configured_file:functions.py:220 19:19:42.849863 [debug] [MainThread]: Parsing macros/materializations/configs.sql
DEBUG    configured_file:functions.py:220 19:19:42.850546 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
DEBUG    configured_file:functions.py:220 19:19:42.850718 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
DEBUG    configured_file:functions.py:220 19:19:42.854966 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
DEBUG    configured_file:functions.py:220 19:19:42.855814 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
DEBUG    configured_file:functions.py:220 19:19:42.856376 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
DEBUG    configured_file:functions.py:220 19:19:42.859047 [debug] [MainThread]: Parsing macros/materializations/models/incremental/helpers.sql
DEBUG    configured_file:functions.py:220 19:19:42.860739 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
DEBUG    configured_file:functions.py:220 19:19:42.864275 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
DEBUG    configured_file:functions.py:220 19:19:42.865145 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
DEBUG    configured_file:functions.py:220 19:19:42.868793 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
DEBUG    configured_file:functions.py:220 19:19:42.870032 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
DEBUG    configured_file:functions.py:220 19:19:42.876910 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
DEBUG    configured_file:functions.py:220 19:19:42.877909 [debug] [MainThread]: Parsing macros/materializations/snapshots/helper.sql
DEBUG    configured_file:functions.py:220 19:19:42.878055 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
DEBUG    configured_file:functions.py:220 19:19:42.883088 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
DEBUG    configured_file:functions.py:220 19:19:42.886541 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
DEBUG    configured_file:functions.py:220 19:19:42.887068 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
DEBUG    configured_file:functions.py:220 19:19:42.887472 [debug] [MainThread]: Parsing macros/adapters/columns.sql
DEBUG    configured_file:functions.py:220 19:19:42.889314 [debug] [MainThread]: Parsing macros/adapters/relation.sql
DEBUG    configured_file:functions.py:220 19:19:42.890879 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
DEBUG    configured_file:functions.py:220 19:19:42.894939 [debug] [MainThread]: Parsing macros/adapters/schema.sql
DEBUG    configured_file:functions.py:220 19:19:42.895768 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
DEBUG    configured_file:functions.py:220 19:19:42.896465 [debug] [MainThread]: Parsing macros/materializations/configs.sql
DEBUG    configured_file:functions.py:220 19:19:42.897819 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
DEBUG    configured_file:functions.py:220 19:19:42.900079 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
DEBUG    configured_file:functions.py:220 19:19:42.900952 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
DEBUG    configured_file:functions.py:220 19:19:42.904137 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
DEBUG    configured_file:functions.py:220 19:19:42.905553 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
DEBUG    configured_file:functions.py:220 19:19:42.907569 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
DEBUG    configured_file:functions.py:220 19:19:42.916637 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
DEBUG    configured_file:functions.py:220 19:19:42.921481 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
DEBUG    configured_file:functions.py:220 19:19:42.922477 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
DEBUG    configured_file:functions.py:220 19:19:42.928972 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
DEBUG    configured_file:functions.py:220 19:19:42.932988 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
DEBUG    configured_file:functions.py:220 19:19:42.942933 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
DEBUG    configured_file:functions.py:220 19:19:42.945033 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
DEBUG    configured_file:functions.py:220 19:19:42.948717 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
DEBUG    configured_file:functions.py:220 19:19:42.957368 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
DEBUG    configured_file:functions.py:220 19:19:42.958660 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
DEBUG    configured_file:functions.py:220 19:19:42.965891 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
DEBUG    configured_file:functions.py:220 19:19:42.976017 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
DEBUG    configured_file:functions.py:220 19:19:42.977450 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
DEBUG    configured_file:functions.py:220 19:19:42.978700 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
DEBUG    configured_file:functions.py:220 19:19:42.981348 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
DEBUG    configured_file:functions.py:220 19:19:42.992170 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
DEBUG    configured_file:functions.py:220 19:19:42.996313 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
DEBUG    configured_file:functions.py:220 19:19:42.997236 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
DEBUG    configured_file:functions.py:220 19:19:42.998197 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
DEBUG    configured_file:functions.py:220 19:19:42.999661 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
DEBUG    configured_file:functions.py:220 19:19:43.000852 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
DEBUG    configured_file:functions.py:220 19:19:43.002470 [debug] [MainThread]: Parsing macros/adapters/columns.sql
DEBUG    configured_file:functions.py:220 19:19:43.008371 [debug] [MainThread]: Parsing macros/adapters/relation.sql
DEBUG    configured_file:functions.py:220 19:19:43.017151 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
DEBUG    configured_file:functions.py:220 19:19:43.021436 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
DEBUG    configured_file:functions.py:220 19:19:43.029487 [debug] [MainThread]: Parsing macros/adapters/schema.sql
DEBUG    configured_file:functions.py:220 19:19:43.030810 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
DEBUG    configured_file:functions.py:220 19:19:43.032833 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
DEBUG    configured_file:functions.py:220 19:19:43.035449 [debug] [MainThread]: Parsing macros/python_model/python.sql
DEBUG    configured_file:functions.py:220 19:19:43.039084 [debug] [MainThread]: Parsing macros/utils/replace.sql
DEBUG    configured_file:functions.py:220 19:19:43.039879 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
DEBUG    configured_file:functions.py:220 19:19:43.040574 [debug] [MainThread]: Parsing macros/utils/any_value.sql
DEBUG    configured_file:functions.py:220 19:19:43.041200 [debug] [MainThread]: Parsing macros/utils/array_append.sql
DEBUG    configured_file:functions.py:220 19:19:43.042069 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
DEBUG    configured_file:functions.py:220 19:19:43.043055 [debug] [MainThread]: Parsing macros/utils/concat.sql
DEBUG    configured_file:functions.py:220 19:19:43.043717 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
DEBUG    configured_file:functions.py:220 19:19:43.044399 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
DEBUG    configured_file:functions.py:220 19:19:43.045139 [debug] [MainThread]: Parsing macros/utils/split_part.sql
DEBUG    configured_file:functions.py:220 19:19:43.046486 [debug] [MainThread]: Parsing macros/utils/intersect.sql
DEBUG    configured_file:functions.py:220 19:19:43.047032 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
DEBUG    configured_file:functions.py:220 19:19:43.048200 [debug] [MainThread]: Parsing macros/utils/right.sql
DEBUG    configured_file:functions.py:220 19:19:43.049167 [debug] [MainThread]: Parsing macros/utils/data_types.sql
DEBUG    configured_file:functions.py:220 19:19:43.053244 [debug] [MainThread]: Parsing macros/utils/literal.sql
DEBUG    configured_file:functions.py:220 19:19:43.053878 [debug] [MainThread]: Parsing macros/utils/datediff.sql
DEBUG    configured_file:functions.py:220 19:19:43.054719 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
DEBUG    configured_file:functions.py:220 19:19:43.055398 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
DEBUG    configured_file:functions.py:220 19:19:43.056247 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
DEBUG    configured_file:functions.py:220 19:19:43.056943 [debug] [MainThread]: Parsing macros/utils/listagg.sql
DEBUG    configured_file:functions.py:220 19:19:43.058436 [debug] [MainThread]: Parsing macros/utils/length.sql
DEBUG    configured_file:functions.py:220 19:19:43.059223 [debug] [MainThread]: Parsing macros/utils/except.sql
DEBUG    configured_file:functions.py:220 19:19:43.059865 [debug] [MainThread]: Parsing macros/utils/hash.sql
DEBUG    configured_file:functions.py:220 19:19:43.060636 [debug] [MainThread]: Parsing macros/utils/position.sql
DEBUG    configured_file:functions.py:220 19:19:43.061398 [debug] [MainThread]: Parsing macros/utils/last_day.sql
DEBUG    configured_file:functions.py:220 19:19:43.062732 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
DEBUG    configured_file:functions.py:220 19:19:43.063613 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
DEBUG    configured_file:functions.py:220 19:19:43.064177 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
DEBUG    configured_file:functions.py:220 19:19:43.064653 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
DEBUG    configured_file:functions.py:220 19:19:43.065378 [debug] [MainThread]: Parsing macros/etc/statement.sql
DEBUG    configured_file:functions.py:220 19:19:43.068812 [debug] [MainThread]: Parsing macros/etc/datetime.sql
DEBUG    configured_file:functions.py:220 19:19:43.073949 [debug] [MainThread]: Parsing tests/generic/builtin.sql
DEBUG    configured_file:functions.py:220 19:19:43.294054 [debug] [MainThread]: 1603: static parser failed on incremental.sql
DEBUG    configured_file:functions.py:220 19:19:43.307723 [debug] [MainThread]: 1602: parser fallback to jinja rendering on incremental.sql
INFO     configured_file:functions.py:222 19:19:43.372319 [info ] [MainThread]: Found 1 model, 0 tests, 0 snapshots, 0 analyses, 296 macros, 0 operations, 2 seed files, 1 source, 0 exposures, 0 metrics
INFO     configured_std_out:functions.py:222 19:19:43  Found 1 model, 0 tests, 0 snapshots, 0 analyses, 296 macros, 0 operations, 2 seed files, 1 source, 0 exposures, 0 metrics
INFO     configured_file:functions.py:222 19:19:43.373857 [info ] [MainThread]: 
INFO     configured_std_out:functions.py:222 19:19:43  
DEBUG    configured_file:functions.py:220 19:19:43.374640 [debug] [MainThread]: Acquiring new vertica connection "master"
DEBUG    configured_file:functions.py:220 19:19:43.375450 [debug] [ThreadPool]: Acquiring new vertica connection "list_VMart"
DEBUG    configured_file:functions.py:220 19:19:43.379610 [debug] [ThreadPool]: Using vertica connection "list_VMart"
DEBUG    configured_file:functions.py:220 19:19:43.379830 [debug] [ThreadPool]: On list_VMart: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "connection_name": "list_VMart"} */

    select schema_name
    from v_catalog.schemata
  
DEBUG    configured_file:functions.py:220 19:19:43.379952 [debug] [ThreadPool]: Opening a new connection, currently in state init
DEBUG    configured_file:functions.py:220 19:19:43.418640 [debug] [ThreadPool]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:43.456676 [debug] [ThreadPool]: SQL status: Code: [Column(name='schema_name', type_code=9, display_size=128, internal_size=-1, precision=None, scale=None, null_ok=True)], Rows: -1, Array Size: 1 in 0.08 seconds
DEBUG    configured_file:functions.py:220 19:19:43.458392 [debug] [ThreadPool]: On list_VMart: Close
DEBUG    configured_file:functions.py:220 19:19:43.460175 [debug] [ThreadPool]: Acquiring new vertica connection "list_VMart_test16664663828075989083_test_basic"
DEBUG    configured_file:functions.py:220 19:19:43.467192 [debug] [ThreadPool]: Using vertica connection "list_VMart_test16664663828075989083_test_basic"
DEBUG    configured_file:functions.py:220 19:19:43.467539 [debug] [ThreadPool]: On list_VMart_test16664663828075989083_test_basic: BEGIN
DEBUG    configured_file:functions.py:220 19:19:43.467728 [debug] [ThreadPool]: Opening a new connection, currently in state closed
DEBUG    configured_file:functions.py:220 19:19:43.513435 [debug] [ThreadPool]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:43.522309 [debug] [ThreadPool]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.05 seconds
DEBUG    configured_file:functions.py:220 19:19:43.522645 [debug] [ThreadPool]: Using vertica connection "list_VMart_test16664663828075989083_test_basic"
DEBUG    configured_file:functions.py:220 19:19:43.522878 [debug] [ThreadPool]: On list_VMart_test16664663828075989083_test_basic: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "connection_name": "list_VMart_test16664663828075989083_test_basic"} */
select
      'VMart' as database,
      table_name as name,
      table_schema as schema,
      'table' as type
    from v_catalog.tables
    where table_schema ilike 'test16664663828075989083_test_basic'
    union all
    select
      'VMart' as database,
      table_name as name,
      table_schema as schema,
      'view' as type
    from v_catalog.views
    where table_schema ilike 'test16664663828075989083_test_basic'
  
DEBUG    configured_file:functions.py:220 19:19:43.541121 [debug] [ThreadPool]: SQL status: Code: [Column(name='database', type_code=9, display_size=5, internal_size=-1, precision=None, scale=None, null_ok=True), Column(name='name', type_code=9, display_size=128, internal_size=-1, precision=None, scale=None, null_ok=True), Column(name='schema', type_code=9, display_size=128, internal_size=-1, precision=None, scale=None, null_ok=True), Column(name='type', type_code=9, display_size=5, internal_size=-1, precision=None, scale=None, null_ok=True)], Rows: -1, Array Size: 1 in 0.02 seconds
DEBUG    configured_file:functions.py:220 19:19:43.542074 [debug] [ThreadPool]: On list_VMart_test16664663828075989083_test_basic: ROLLBACK
DEBUG    configured_file:functions.py:220 19:19:43.548866 [debug] [ThreadPool]: On list_VMart_test16664663828075989083_test_basic: Close
DEBUG    configured_file:functions.py:220 19:19:43.549995 [debug] [MainThread]: Using vertica connection "master"
DEBUG    configured_file:functions.py:220 19:19:43.550295 [debug] [MainThread]: On master: BEGIN
DEBUG    configured_file:functions.py:220 19:19:43.550488 [debug] [MainThread]: Opening a new connection, currently in state init
DEBUG    configured_file:functions.py:220 19:19:43.595694 [debug] [MainThread]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:43.603293 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.05 seconds
DEBUG    configured_file:functions.py:220 19:19:43.603557 [debug] [MainThread]: On master: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.603699 [debug] [MainThread]: Using vertica connection "master"
DEBUG    configured_file:functions.py:220 19:19:43.603807 [debug] [MainThread]: On master: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.614286 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.01 seconds
DEBUG    configured_file:functions.py:220 19:19:43.614573 [debug] [MainThread]: On master: Close
INFO     configured_file:functions.py:222 19:19:43.615083 [info ] [MainThread]: Concurrency: 4 threads (target='default')
INFO     configured_std_out:functions.py:222 19:19:43  Concurrency: 4 threads (target='default')
INFO     configured_file:functions.py:222 19:19:43.615358 [info ] [MainThread]: 
INFO     configured_std_out:functions.py:222 19:19:43  
DEBUG    configured_file:functions.py:220 19:19:43.618076 [debug] [Thread-1 (]: Began running node seed.incremental.added
DEBUG    configured_file:functions.py:220 19:19:43.618235 [debug] [Thread-2 (]: Began running node seed.incremental.base
INFO     configured_file:functions.py:222 19:19:43.618508 [info ] [Thread-1 (]: 1 of 2 START seed file test16664663828075989083_test_basic.added ............... [RUN]
INFO     configured_std_out:functions.py:222 19:19:43  1 of 2 START seed file test16664663828075989083_test_basic.added ............... [RUN]
INFO     configured_file:functions.py:222 19:19:43.618728 [info ] [Thread-2 (]: 2 of 2 START seed file test16664663828075989083_test_basic.base ................ [RUN]
INFO     configured_std_out:functions.py:222 19:19:43  2 of 2 START seed file test16664663828075989083_test_basic.base ................ [RUN]
DEBUG    configured_file:functions.py:220 19:19:43.619366 [debug] [Thread-1 (]: Acquiring new vertica connection "seed.incremental.added"
DEBUG    configured_file:functions.py:220 19:19:43.620122 [debug] [Thread-2 (]: Acquiring new vertica connection "seed.incremental.base"
DEBUG    configured_file:functions.py:220 19:19:43.620353 [debug] [Thread-1 (]: Began compiling node seed.incremental.added
DEBUG    configured_file:functions.py:220 19:19:43.620538 [debug] [Thread-2 (]: Began compiling node seed.incremental.base
DEBUG    configured_file:functions.py:220 19:19:43.620747 [debug] [Thread-1 (]: finished collecting timing info
DEBUG    configured_file:functions.py:220 19:19:43.620912 [debug] [Thread-2 (]: finished collecting timing info
DEBUG    configured_file:functions.py:220 19:19:43.621111 [debug] [Thread-1 (]: Began executing node seed.incremental.added
DEBUG    configured_file:functions.py:220 19:19:43.621282 [debug] [Thread-2 (]: Began executing node seed.incremental.base
DEBUG    configured_file:functions.py:220 19:19:43.670313 [debug] [Thread-1 (]: Writing runtime sql for node "seed.incremental.added"
DEBUG    configured_file:functions.py:220 19:19:43.672615 [debug] [Thread-2 (]: Writing runtime sql for node "seed.incremental.base"
DEBUG    configured_file:functions.py:220 19:19:43.673239 [debug] [Thread-2 (]: Using vertica connection "seed.incremental.base"
DEBUG    configured_file:functions.py:220 19:19:43.673413 [debug] [Thread-1 (]: Using vertica connection "seed.incremental.added"
DEBUG    configured_file:functions.py:220 19:19:43.673609 [debug] [Thread-2 (]: On seed.incremental.base: BEGIN
DEBUG    configured_file:functions.py:220 19:19:43.673775 [debug] [Thread-1 (]: On seed.incremental.added: BEGIN
DEBUG    configured_file:functions.py:220 19:19:43.674012 [debug] [Thread-2 (]: Opening a new connection, currently in state init
DEBUG    configured_file:functions.py:220 19:19:43.674240 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
DEBUG    configured_file:functions.py:220 19:19:43.700573 [debug] [Thread-2 (]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:43.703837 [debug] [Thread-1 (]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:43.711701 [debug] [Thread-2 (]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.04 seconds
DEBUG    configured_file:functions.py:220 19:19:43.712016 [debug] [Thread-1 (]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.04 seconds
DEBUG    configured_file:functions.py:220 19:19:43.712364 [debug] [Thread-2 (]: Using vertica connection "seed.incremental.base"
DEBUG    configured_file:functions.py:220 19:19:43.712619 [debug] [Thread-1 (]: Using vertica connection "seed.incremental.added"
DEBUG    configured_file:functions.py:220 19:19:43.712846 [debug] [Thread-2 (]: On seed.incremental.base: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "node_id": "seed.incremental.base"} */

    
    create table "VMart"."test16664663828075989083_test_basic"."base" ("id" integer,"name" varchar(8),"some_date" timestamp without time zone)
  ;
    -- dbt seed --
    
        copy "VMart"."test16664663828075989083_test_basic"."base"
        ("id", "name", "some_date")
        from local '/tmp/pytest-of-sachin/pytest-119/project0/seeds/base.csv'
        delimiter ','
        enclosed by '"'
        skip 1
        abort on error
        rejected data as table "VMart"."test16664663828075989083_test_basic".seed_rejects;
    
  
DEBUG    configured_file:functions.py:220 19:19:43.713053 [debug] [Thread-1 (]: On seed.incremental.added: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "node_id": "seed.incremental.added"} */

    
    create table "VMart"."test16664663828075989083_test_basic"."added" ("id" integer,"name" varchar(9),"some_date" timestamp without time zone)
  ;
    -- dbt seed --
    
        copy "VMart"."test16664663828075989083_test_basic"."added"
        ("id", "name", "some_date")
        from local '/tmp/pytest-of-sachin/pytest-119/project0/seeds/added.csv'
        delimiter ','
        enclosed by '"'
        skip 1
        abort on error
        rejected data as table "VMart"."test16664663828075989083_test_basic".seed_rejects;
    
  
DEBUG    configured_file:functions.py:220 19:19:43.787294 [debug] [Thread-2 (]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.07 seconds
DEBUG    configured_file:functions.py:220 19:19:43.799630 [debug] [Thread-2 (]: On seed.incremental.base: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.799983 [debug] [Thread-2 (]: Using vertica connection "seed.incremental.base"
DEBUG    configured_file:functions.py:220 19:19:43.800197 [debug] [Thread-2 (]: On seed.incremental.base: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.801743 [debug] [Thread-1 (]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.09 seconds
DEBUG    configured_file:functions.py:220 19:19:43.803029 [debug] [Thread-1 (]: On seed.incremental.added: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.803238 [debug] [Thread-1 (]: Using vertica connection "seed.incremental.added"
DEBUG    configured_file:functions.py:220 19:19:43.803429 [debug] [Thread-1 (]: On seed.incremental.added: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.825612 [debug] [Thread-1 (]: vertica adapter: :P Database error: Severity: ROLLBACK, Message: Object "seed_rejects" already exists, Sqlstate: 42710, Routine: outputAlreadyExistsEreport, File: /data/jenkins/workspace/RE-ReleaseBuilds/RE-Knuckleboom/server/vertica/Commands/DDL.cpp, Line: 25505, Error Code: 4213, SQL: '/* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "node_id": "seed.incremental.added"} */          create table "VMart"."test16664663828075989083_test_basic"."added" ("id" integer,"name" varchar(9),"some_date" timestamp without time zone)   ;     -- dbt seed --              copy "VMart"."test16664663828075989083_test_basic"."added"         ("id", "name", "some_date")         from local \'/tmp/pytest-of-sachin/pytest-119/project0/seeds/added.csv\'         delimiter \',\'         enclosed by \'"\'         skip 1         abort on error         rejected data as table "VMart"."test16664663828075989083_test_basic".seed_rejects;        '
DEBUG    configured_file:functions.py:220 19:19:43.825927 [debug] [Thread-1 (]: On seed.incremental.added: ROLLBACK
DEBUG    configured_file:functions.py:220 19:19:43.865229 [debug] [Thread-1 (]: On seed.incremental.added: Close
DEBUG    configured_file:functions.py:220 19:19:43.865897 [debug] [Thread-1 (]: finished collecting timing info
DEBUG    configured_file:functions.py:220 19:19:43.866573 [debug] [Thread-1 (]: Database Error in seed added (seeds/added.csv)
  Severity: ROLLBACK, Message: Object "seed_rejects" already exists, Sqlstate: 42710, Routine: outputAlreadyExistsEreport, File: /data/jenkins/workspace/RE-ReleaseBuilds/RE-Knuckleboom/server/vertica/Commands/DDL.cpp, Line: 25505, Error Code: 4213, SQL: '/* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "node_id": "seed.incremental.added"} */          create table "VMart"."test16664663828075989083_test_basic"."added" ("id" integer,"name" varchar(9),"some_date" timestamp without time zone)   ;     -- dbt seed --              copy "VMart"."test16664663828075989083_test_basic"."added"         ("id", "name", "some_date")         from local \'/tmp/pytest-of-sachin/pytest-119/project0/seeds/added.csv\'         delimiter \',\'         enclosed by \'"\'         skip 1         abort on error         rejected data as table "VMart"."test16664663828075989083_test_basic".seed_rejects;        '
  compiled Code at target/run/incremental/seeds/added.csv
ERROR    configured_file:functions.py:226 19:19:43.866924 [error] [Thread-1 (]: 1 of 2 ERROR loading seed file test16664663828075989083_test_basic.added ....... [ERROR in 0.25s]
ERROR    configured_std_out:functions.py:226 19:19:43  1 of 2 ERROR loading seed file test16664663828075989083_test_basic.added ....... [ERROR in 0.25s]
DEBUG    configured_file:functions.py:220 19:19:43.867445 [debug] [Thread-1 (]: Finished running node seed.incremental.added
DEBUG    configured_file:functions.py:220 19:19:43.902447 [debug] [Thread-2 (]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.1 seconds
DEBUG    configured_file:functions.py:220 19:19:43.903350 [debug] [Thread-2 (]: finished collecting timing info
DEBUG    configured_file:functions.py:220 19:19:43.903658 [debug] [Thread-2 (]: On seed.incremental.base: Close
INFO     configured_file:functions.py:222 19:19:43.904397 [info ] [Thread-2 (]: 2 of 2 OK loaded seed file test16664663828075989083_test_basic.base ............ [Code: None, Rows: -1, Array Size: 1 in 0.28s]
INFO     configured_std_out:functions.py:222 19:19:43  2 of 2 OK loaded seed file test16664663828075989083_test_basic.base ............ [Code: None, Rows: -1, Array Size: 1 in 0.28s]
DEBUG    configured_file:functions.py:220 19:19:43.904906 [debug] [Thread-2 (]: Finished running node seed.incremental.base
DEBUG    configured_file:functions.py:220 19:19:43.905961 [debug] [MainThread]: Acquiring new vertica connection "master"
DEBUG    configured_file:functions.py:220 19:19:43.906235 [debug] [MainThread]: Using vertica connection "master"
DEBUG    configured_file:functions.py:220 19:19:43.906419 [debug] [MainThread]: On master: BEGIN
DEBUG    configured_file:functions.py:220 19:19:43.906598 [debug] [MainThread]: Opening a new connection, currently in state closed
DEBUG    configured_file:functions.py:220 19:19:43.932606 [debug] [MainThread]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:43.942813 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.04 seconds
DEBUG    configured_file:functions.py:220 19:19:43.943050 [debug] [MainThread]: On master: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.943174 [debug] [MainThread]: Using vertica connection "master"
DEBUG    configured_file:functions.py:220 19:19:43.943291 [debug] [MainThread]: On master: COMMIT
DEBUG    configured_file:functions.py:220 19:19:43.951620 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.01 seconds
DEBUG    configured_file:functions.py:220 19:19:43.951916 [debug] [MainThread]: On master: Close
INFO     configured_file:functions.py:222 19:19:43.952665 [info ] [MainThread]: 
INFO     configured_std_out:functions.py:222 19:19:43  
INFO     configured_file:functions.py:222 19:19:43.953102 [info ] [MainThread]: Finished running 2 seeds in 0 hours 0 minutes and 0.58 seconds (0.58s).
INFO     configured_std_out:functions.py:222 19:19:43  Finished running 2 seeds in 0 hours 0 minutes and 0.58 seconds (0.58s).
DEBUG    configured_file:functions.py:220 19:19:43.953486 [debug] [MainThread]: Connection 'master' was properly closed.
DEBUG    configured_file:functions.py:220 19:19:43.953677 [debug] [MainThread]: Connection 'seed.incremental.added' was properly closed.
DEBUG    configured_file:functions.py:220 19:19:43.953853 [debug] [MainThread]: Connection 'seed.incremental.base' was properly closed.
INFO     configured_file:functions.py:222 19:19:43.962055 [info ] [MainThread]: 
INFO     configured_std_out:functions.py:222 19:19:43  
INFO     configured_file:functions.py:222 19:19:43.962667 [info ] [MainThread]: Completed with 1 error and 0 warnings:
INFO     configured_std_out:functions.py:222 19:19:43  Completed with 1 error and 0 warnings:
INFO     configured_file:functions.py:222 19:19:43.963168 [info ] [MainThread]: 
INFO     configured_std_out:functions.py:222 19:19:43  
ERROR    configured_file:functions.py:226 19:19:43.963591 [error] [MainThread]: Database Error in seed added (seeds/added.csv)
ERROR    configured_std_out:functions.py:226 19:19:43  Database Error in seed added (seeds/added.csv)
ERROR    configured_file:functions.py:226 19:19:43.964001 [error] [MainThread]:   Severity: ROLLBACK, Message: Object "seed_rejects" already exists, Sqlstate: 42710, Routine: outputAlreadyExistsEreport, File: /data/jenkins/workspace/RE-ReleaseBuilds/RE-Knuckleboom/server/vertica/Commands/DDL.cpp, Line: 25505, Error Code: 4213, SQL: '/* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "node_id": "seed.incremental.added"} */          create table "VMart"."test16664663828075989083_test_basic"."added" ("id" integer,"name" varchar(9),"some_date" timestamp without time zone)   ;     -- dbt seed --              copy "VMart"."test16664663828075989083_test_basic"."added"         ("id", "name", "some_date")         from local \'/tmp/pytest-of-sachin/pytest-119/project0/seeds/added.csv\'         delimiter \',\'         enclosed by \'"\'         skip 1         abort on error         rejected data as table "VMart"."test16664663828075989083_test_basic".seed_rejects;        '
ERROR    configured_std_out:functions.py:226 19:19:43    Severity: ROLLBACK, Message: Object "seed_rejects" already exists, Sqlstate: 42710, Routine: outputAlreadyExistsEreport, File: /data/jenkins/workspace/RE-ReleaseBuilds/RE-Knuckleboom/server/vertica/Commands/DDL.cpp, Line: 25505, Error Code: 4213, SQL: '/* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "node_id": "seed.incremental.added"} */          create table "VMart"."test16664663828075989083_test_basic"."added" ("id" integer,"name" varchar(9),"some_date" timestamp without time zone)   ;     -- dbt seed --              copy "VMart"."test16664663828075989083_test_basic"."added"         ("id", "name", "some_date")         from local \'/tmp/pytest-of-sachin/pytest-119/project0/seeds/added.csv\'         delimiter \',\'         enclosed by \'"\'         skip 1         abort on error         rejected data as table "VMart"."test16664663828075989083_test_basic".seed_rejects;        '
ERROR    configured_file:functions.py:226 19:19:43.964432 [error] [MainThread]:   compiled Code at target/run/incremental/seeds/added.csv
ERROR    configured_std_out:functions.py:226 19:19:43    compiled Code at target/run/incremental/seeds/added.csv
INFO     configured_file:functions.py:222 19:19:43.964861 [info ] [MainThread]: 
INFO     configured_std_out:functions.py:222 19:19:43  
INFO     configured_file:functions.py:222 19:19:43.965297 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
INFO     configured_std_out:functions.py:222 19:19:43  Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
DEBUG    configured_file:functions.py:220 19:19:43.965851 [debug] [MainThread]: Flushing usage events
------------------------------------------------------------------------------------ Captured log teardown ------------------------------------------------------------------------------------
DEBUG    configured_file:functions.py:220 19:19:44.024840 [debug] [MainThread]: Acquiring new vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:44.025193 [debug] [MainThread]: Dropping schema "_ReferenceKey(database='vmart', schema='test16664663828075989083_test_basic', identifier=None)".
DEBUG    configured_file:functions.py:220 19:19:44.028596 [debug] [MainThread]: Using vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:44.028760 [debug] [MainThread]: On _test: BEGIN
DEBUG    configured_file:functions.py:220 19:19:44.028869 [debug] [MainThread]: Opening a new connection, currently in state init
DEBUG    configured_file:functions.py:220 19:19:44.069166 [debug] [MainThread]: vertica adapter: :P Connected to database: VMart at 159.65.150.255
DEBUG    configured_file:functions.py:220 19:19:44.078662 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.05 seconds
DEBUG    configured_file:functions.py:220 19:19:44.079066 [debug] [MainThread]: Using vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:44.079320 [debug] [MainThread]: On _test: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "test", "target_name": "default", "connection_name": "_test"} */
drop schema if exists "test16664663828075989083_test_basic" cascade
  
DEBUG    configured_file:functions.py:220 19:19:44.126150 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.05 seconds
DEBUG    configured_file:functions.py:220 19:19:44.128080 [debug] [MainThread]: On _test: COMMIT
DEBUG    configured_file:functions.py:220 19:19:44.128540 [debug] [MainThread]: Using vertica connection "_test"
DEBUG    configured_file:functions.py:220 19:19:44.128899 [debug] [MainThread]: On _test: COMMIT
DEBUG    configured_file:functions.py:220 19:19:44.137313 [debug] [MainThread]: SQL status: Code: None, Rows: -1, Array Size: 1 in 0.01 seconds
DEBUG    configured_file:functions.py:220 19:19:44.138027 [debug] [MainThread]: On _test: Close
DEBUG    configured_file:functions.py:220 19:19:44.139794 [debug] [MainThread]: Connection '_test' was properly closed.
=================================================================================== short test summary info ===================================================================================
FAILED functional/adapter/test_basic.py::TestIncrementalVertica::test_incremental - AssertionError: dbt exit state did not match expected
====================================================================================== 1 failed in 1.76s =================================================================================